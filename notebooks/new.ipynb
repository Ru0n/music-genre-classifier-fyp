{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: light\n",
    "#       format_version: '1.5'\n",
    "#       jupytext_version: 1.16.1\n",
    "#   kernelspec:\n",
    "#     display_name: Python 3 (ipykernel)\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---\n",
    "\n",
    "# # Enhanced Custom Music Genre Classification Model\n",
    "\n",
    "# ## Overview\n",
    "# This notebook builds upon previous iterations to create a potentially more robust custom CNN model for genre classification using Mel Spectrograms from the GTZAN dataset.\n",
    "#\n",
    "# **Key Features & Improvements:**\n",
    "# 1.  **Mel Spectrogram Input:** Uses dB-scaled Mel spectrograms.\n",
    "# 2.  **Global Normalization:** Correctly applies Min-Max scaling based on the training set.\n",
    "# 3.  **Data Augmentation:** Integrates Frequency and Time Masking directly into the model using custom layers.\n",
    "# 4.  **Refined CNN Architecture:** A slightly deeper CNN with consistent application of Batch Normalization, Pooling, Dropout, and L2 Regularization.\n",
    "# 5.  **Robust Training:** Uses EarlyStopping, ReduceLROnPlateau, and ModelCheckpoint callbacks.\n",
    "# 6.  **Modern Saving Format:** Uses the recommended '.keras' format.\n",
    "# 7.  **Reproducibility:** Sets random seeds.\n",
    "# 8.  **Comprehensive Evaluation:** Includes history plots, test set evaluation, confusion matrix, and classification report.\n",
    "#\n",
    "# **Note:** This model is built *from scratch* and does *not* use transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2 # Import L2 regularizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paths ---\n",
    "# Adjust this path to where your GTZAN 'genres_original' folder is located\n",
    "RAW_DATA_PATH = '../data/raw/GTZAN/genres_original'\n",
    "# Adjust this path to where your pre-processed '.npy' spectrogram files are located\n",
    "SPECTROGRAM_NPY_PATH = '../data/processed/spectrograms_npy'\n",
    "# Path to save the best model\n",
    "MODEL_SAVE_DIR = '../model'\n",
    "BEST_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, 'best_custom_cnn_genre_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Audio Parameters ---\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 30  # GTZAN duration\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Target Spectrogram Length (Time Bins): 1292\n"
     ]
    }
   ],
   "source": [
    "# --- Spectrogram Parameters ---\n",
    "N_MELS = 128   # Number of Mel bands\n",
    "N_FFT = 2048   # Window size for FFT\n",
    "HOP_LENGTH = 512 # Hop length for STFT\n",
    "\n",
    "# Calculate expected spectrogram length (time bins)\n",
    "# Using math.ceil ensures we capture the last frame\n",
    "EXPECTED_LENGTH = math.ceil(SAMPLES_PER_TRACK / HOP_LENGTH)\n",
    "print(f\"Using Target Spectrogram Length (Time Bins): {EXPECTED_LENGTH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Genre Classes ---\n",
    "GENRES = sorted([\n",
    "    'blues', 'classical', 'country', 'disco', 'hiphop',\n",
    "    'jazz', 'metal', 'pop', 'reggae', 'rock'\n",
    "]) # Sorting ensures consistent order\n",
    "NUM_GENRES = len(GENRES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Augmentation Parameters ---\n",
    "FREQ_MASK_PARAM = 25 # Max number of frequency bands to mask (Adjusted slightly)\n",
    "TIME_MASK_PARAM = 40 # Max number of time steps to mask (Adjusted slightly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Parameters ---\n",
    "EPOCHS = 150      # Max epochs (EarlyStopping will likely stop it sooner)\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2 # Use 20% of training data for validation during training\n",
    "LEARNING_RATE = 1e-4 # Initial learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reproducibility ---\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "# Optional: Determinism (can impact performance)\n",
    "# tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create Model Save Directory ---\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 3. Data Loading & Preprocessing\n",
    "\n",
    "# Check if pre-processed data exists, otherwise generate spectrograms\n",
    "# For this notebook, we assume the '.npy' files exist from a previous step.\n",
    "# If not, you would add the code from the previous notebook here to generate them from RAW_DATA_PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spectrograms from: ../data/processed/spectrograms_npy\n",
      "Loading blues spectrograms...\n",
      " -> Loaded 100 files for blues.\n",
      "Loading classical spectrograms...\n",
      " -> Loaded 100 files for classical.\n",
      "Loading country spectrograms...\n",
      " -> Loaded 100 files for country.\n",
      "Loading disco spectrograms...\n",
      " -> Loaded 100 files for disco.\n",
      "Loading hiphop spectrograms...\n",
      " -> Loaded 100 files for hiphop.\n",
      "Loading jazz spectrograms...\n",
      " -> Loaded 99 files for jazz.\n",
      "Loading metal spectrograms...\n",
      " -> Loaded 100 files for metal.\n",
      "Loading pop spectrograms...\n",
      " -> Loaded 100 files for pop.\n",
      "Loading reggae spectrograms...\n",
      " -> Loaded 100 files for reggae.\n",
      "Loading rock spectrograms...\n",
      " -> Loaded 100 files for rock.\n",
      "\n",
      "Loaded 999 total spectrograms.\n",
      "Shape of spectrogram array: (999, 128, 1292)\n"
     ]
    }
   ],
   "source": [
    "# Function to resize spectrograms\n",
    "def resize_spectrogram(spec, target_length):\n",
    "    current_length = spec.shape[1]\n",
    "    if current_length > target_length:\n",
    "        return spec[:, :target_length] # Truncate\n",
    "    elif current_length < target_length:\n",
    "        # Pad with the minimum value of the spectrogram (often silence)\n",
    "        padding_value = np.min(spec)\n",
    "        padding = np.full((spec.shape[0], target_length - current_length), padding_value)\n",
    "        return np.hstack((spec, padding)) # Pad\n",
    "    else:\n",
    "        return spec\n",
    "\n",
    "# Load all spectrograms from individual files\n",
    "spectrograms = []\n",
    "labels = []\n",
    "\n",
    "print(f\"Loading spectrograms from: {SPECTROGRAM_NPY_PATH}\")\n",
    "if not os.path.exists(SPECTROGRAM_NPY_PATH):\n",
    "     raise FileNotFoundError(f\"Spectrogram directory not found: {SPECTROGRAM_NPY_PATH}. \"\n",
    "                             \"Please ensure spectrograms have been generated and saved as .npy files.\")\n",
    "\n",
    "for genre_idx, genre in enumerate(GENRES):\n",
    "    genre_path = os.path.join(SPECTROGRAM_NPY_PATH, genre)\n",
    "    if os.path.exists(genre_path):\n",
    "        print(f'Loading {genre} spectrograms...')\n",
    "        files_loaded = 0\n",
    "        for file in os.listdir(genre_path):\n",
    "            if file.endswith('.npy'):\n",
    "                try:\n",
    "                    spec = np.load(os.path.join(genre_path, file))\n",
    "                    # Ensure spec is 2D (Mel Bands, Time) and has expected number of Mel bands\n",
    "                    if spec.ndim == 2 and spec.shape[0] == N_MELS:\n",
    "                        resized_spec = resize_spectrogram(spec, EXPECTED_LENGTH)\n",
    "                        # Check final shape\n",
    "                        if resized_spec.shape == (N_MELS, EXPECTED_LENGTH):\n",
    "                            spectrograms.append(resized_spec)\n",
    "                            labels.append(genre_idx)\n",
    "                            files_loaded += 1\n",
    "                        else:\n",
    "                            print(f\"Skipping {file} - incorrect shape after resize: {resized_spec.shape}\")\n",
    "                    else:\n",
    "                        print(f\"Skipping {file} - unexpected shape {spec.shape} or wrong Mel bands\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading or processing {file}: {e}\")\n",
    "        print(f\" -> Loaded {files_loaded} files for {genre}.\")\n",
    "    else:\n",
    "        print(f\"Warning: Genre directory not found: {genre_path}\")\n",
    "\n",
    "\n",
    "if not spectrograms:\n",
    "    raise ValueError(\"No spectrograms loaded. Check path and file contents.\")\n",
    "\n",
    "spectrograms = np.array(spectrograms)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"\\nLoaded {len(spectrograms)} total spectrograms.\")\n",
    "if len(spectrograms) > 0:\n",
    "    print(f\"Shape of spectrogram array: {spectrograms.shape}\") # (num_samples, N_MELS, EXPECTED_LENGTH)\n",
    "else:\n",
    "     raise ValueError(\"Spectrogram list is empty after loading.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing data for training...\n",
      "Data shape after adding channel: (999, 128, 1292, 1)\n",
      "Labels shape after one-hot encoding: (999, 10)\n",
      "Training set shape:   (639, 128, 1292, 1), (639, 10)\n",
      "Validation set shape: (160, 128, 1292, 1), (160, 10)\n",
      "Testing set shape:    (200, 128, 1292, 1), (200, 10)\n"
     ]
    }
   ],
   "source": [
    "# ## 4. Prepare Data for Training\n",
    "\n",
    "print(\"\\nPreparing data for training...\")\n",
    "\n",
    "# --- Add Channel Dimension ---\n",
    "if spectrograms.ndim == 3:\n",
    "    X = spectrograms[..., np.newaxis]\n",
    "    print(f\"Data shape after adding channel: {X.shape}\") # (num_samples, N_MELS, EXPECTED_LENGTH, 1)\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected spectrogram array dimension: {spectrograms.ndim}. Expected 3.\")\n",
    "\n",
    "# --- Encode Labels ---\n",
    "y = to_categorical(labels, num_classes=NUM_GENRES)\n",
    "print(f\"Labels shape after one-hot encoding: {y.shape}\")\n",
    "\n",
    "# --- Train/Validation/Test Split ---\n",
    "# First split into Train (80%) and Test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=y # Ensure proportional representation of genres\n",
    ")\n",
    "\n",
    "# Then split Train into Train (80% of original 80% = 64%) and Validation (20% of original 80% = 16%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2, # 0.2 of the 80% = 16% of total\n",
    "    random_state=SEED,\n",
    "    stratify=y_train # Stratify based on the training labels\n",
    ")\n",
    "\n",
    "print(f\"Training set shape:   {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Testing set shape:    {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying global Min-Max normalization...\n",
      "Normalization complete.\n",
      "Scaled X_train min: 0.0000, max: 1.0000\n",
      "Scaled X_val min: -0.3909, max: 1.2813\n",
      "Scaled X_test min: -0.3736, max: 1.2646\n"
     ]
    }
   ],
   "source": [
    "# --- Global Normalization (Min-Max Scaling) ---\n",
    "print(\"Applying global Min-Max normalization...\")\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Reshape data for scaler (flatten frequency and time dimensions)\n",
    "original_train_shape = X_train.shape\n",
    "original_val_shape = X_val.shape\n",
    "original_test_shape = X_test.shape\n",
    "\n",
    "X_train_reshaped = X_train.reshape(original_train_shape[0], -1)\n",
    "X_val_reshaped = X_val.reshape(original_val_shape[0], -1)\n",
    "X_test_reshaped = X_test.reshape(original_test_shape[0], -1)\n",
    "\n",
    "# Fit scaler ONLY on the training data\n",
    "scaler.fit(X_train_reshaped)\n",
    "\n",
    "# Transform all datasets\n",
    "X_train_scaled_reshaped = scaler.transform(X_train_reshaped)\n",
    "X_val_scaled_reshaped = scaler.transform(X_val_reshaped)\n",
    "X_test_scaled_reshaped = scaler.transform(X_test_reshaped)\n",
    "\n",
    "# Reshape back to original image format (with channel dimension)\n",
    "X_train = X_train_scaled_reshaped.reshape(original_train_shape)\n",
    "X_val = X_val_scaled_reshaped.reshape(original_val_shape)\n",
    "X_test = X_test_scaled_reshaped.reshape(original_test_shape)\n",
    "\n",
    "print(\"Normalization complete.\")\n",
    "print(f\"Scaled X_train min: {np.min(X_train):.4f}, max: {np.max(X_train):.4f}\")\n",
    "print(f\"Scaled X_val min: {np.min(X_val):.4f}, max: {np.max(X_val):.4f}\")\n",
    "print(f\"Scaled X_test min: {np.min(X_test):.4f}, max: {np.max(X_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 5. Custom Augmentation Layers\n",
    "\n",
    "# Registering custom layers allows saving/loading models that use them\n",
    "@register_keras_serializable(package=\"Custom\", name=\"FrequencyMasking\")\n",
    "class FrequencyMasking(layers.Layer):\n",
    "    \"\"\"Applies Frequency Masking augmentation.\"\"\"\n",
    "    def __init__(self, freq_mask_param, name=\"frequency_masking\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.freq_mask_param = freq_mask_param\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training is None: # Handle case during model build\n",
    "            training = False\n",
    "\n",
    "        def apply_augmentation():\n",
    "            n_mels = tf.shape(inputs)[1] # Frequency dimension\n",
    "            f = tf.random.uniform(shape=(), minval=0, maxval=self.freq_mask_param + 1, dtype=tf.int32)\n",
    "            def perform_mask():\n",
    "                f0 = tf.random.uniform(shape=(), minval=0, maxval=n_mels - f, dtype=tf.int32)\n",
    "                mask_value = 0.0 # Mask with zero (assuming normalized input near zero)\n",
    "                mask = tf.concat(\n",
    "                    [tf.ones(shape=(1, f0, 1, 1), dtype=inputs.dtype),\n",
    "                     tf.fill(dims=(1, f, 1, 1), value=mask_value),\n",
    "                     tf.ones(shape=(1, n_mels - f0 - f, 1, 1), dtype=inputs.dtype)],\n",
    "                    axis=1\n",
    "                )\n",
    "                # Ensure mask aligns with the batch dimension\n",
    "                batch_size = tf.shape(inputs)[0]\n",
    "                mask_repeated = tf.tile(mask, [batch_size, 1, tf.shape(inputs)[2], 1])\n",
    "                return inputs * mask_repeated\n",
    "\n",
    "            # Only apply if f > 0\n",
    "            return tf.cond(tf.greater(f, 0), true_fn=perform_mask, false_fn=lambda: inputs)\n",
    "\n",
    "        # Apply augmentation only during training\n",
    "        return tf.cond(tf.cast(training, tf.bool),\n",
    "                       true_fn=apply_augmentation,\n",
    "                       false_fn=lambda: inputs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"freq_mask_param\": self.freq_mask_param})\n",
    "        return config\n",
    "\n",
    "@register_keras_serializable(package=\"Custom\", name=\"TimeMasking\")\n",
    "class TimeMasking(layers.Layer):\n",
    "    \"\"\"Applies Time Masking augmentation.\"\"\"\n",
    "    def __init__(self, time_mask_param, name=\"time_masking\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.time_mask_param = time_mask_param\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training is None:\n",
    "             training = False\n",
    "\n",
    "        def apply_augmentation():\n",
    "            time_steps = tf.shape(inputs)[2] # Time dimension\n",
    "            t = tf.random.uniform(shape=(), minval=0, maxval=self.time_mask_param + 1, dtype=tf.int32)\n",
    "            def perform_mask():\n",
    "                t0 = tf.random.uniform(shape=(), minval=0, maxval=time_steps - t, dtype=tf.int32)\n",
    "                mask_value = 0.0\n",
    "                mask = tf.concat(\n",
    "                    [tf.ones(shape=(1, 1, t0, 1), dtype=inputs.dtype),\n",
    "                     tf.fill(dims=(1, 1, t, 1), value=mask_value),\n",
    "                     tf.ones(shape=(1, 1, time_steps - t0 - t, 1), dtype=inputs.dtype)],\n",
    "                    axis=2 # Concatenate along the time axis\n",
    "                )\n",
    "                batch_size = tf.shape(inputs)[0]\n",
    "                mask_repeated = tf.tile(mask, [batch_size, tf.shape(inputs)[1], 1, 1])\n",
    "                return inputs * mask_repeated\n",
    "\n",
    "            return tf.cond(tf.greater(t, 0), true_fn=perform_mask, false_fn=lambda: inputs)\n",
    "\n",
    "        return tf.cond(tf.cast(training, tf.bool),\n",
    "                       true_fn=apply_augmentation,\n",
    "                       false_fn=lambda: inputs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"time_mask_param\": self.time_mask_param})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 6. Build \"Best Case\" Custom CNN Model (No Transfer Learning)\n",
    "\n",
    "def build_custom_cnn_model(input_shape, num_genres, l2_reg=0.001):\n",
    "    \"\"\"Builds a refined custom CNN model with regularization.\"\"\"\n",
    "\n",
    "    model = models.Sequential(name=\"Custom_CNN_Genre_Classifier\")\n",
    "\n",
    "    # Input Layer + Augmentation\n",
    "    model.add(layers.Input(shape=input_shape, name=\"Input\"))\n",
    "    model.add(FrequencyMasking(freq_mask_param=FREQ_MASK_PARAM, name=\"FreqMask\"))\n",
    "    model.add(TimeMasking(time_mask_param=TIME_MASK_PARAM, name=\"TimeMask\"))\n",
    "    # Optional: Add Gaussian Noise for more augmentation\n",
    "    # model.add(layers.GaussianNoise(0.05, name=\"GaussianNoise\"))\n",
    "\n",
    "    # --- Feature Extraction Blocks ---\n",
    "\n",
    "    # Block 1\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), name=\"Conv1_1\"))\n",
    "    model.add(layers.BatchNormalization(name=\"BN1_1\"))\n",
    "    model.add(layers.Activation('relu', name=\"Relu1_1\"))\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), name=\"Conv1_2\")) # Added second conv\n",
    "    model.add(layers.BatchNormalization(name=\"BN1_2\"))\n",
    "    model.add(layers.Activation('relu', name=\"Relu1_2\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"Pool1\"))\n",
    "    model.add(layers.Dropout(0.25, name=\"Drop1\")) # Dropout after pooling\n",
    "\n",
    "    # Block 2\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), name=\"Conv2_1\"))\n",
    "    model.add(layers.BatchNormalization(name=\"BN2_1\"))\n",
    "    model.add(layers.Activation('relu', name=\"Relu2_1\"))\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), name=\"Conv2_2\")) # Added second conv\n",
    "    model.add(layers.BatchNormalization(name=\"BN2_2\"))\n",
    "    model.add(layers.Activation('relu', name=\"Relu2_2\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"Pool2\"))\n",
    "    model.add(layers.Dropout(0.25, name=\"Drop2\"))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), name=\"Conv3_1\"))\n",
    "    model.add(layers.BatchNormalization(name=\"BN3_1\"))\n",
    "    model.add(layers.Activation('relu', name=\"Relu3_1\"))\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), name=\"Conv3_2\")) # Added second conv\n",
    "    model.add(layers.BatchNormalization(name=\"BN3_2\"))\n",
    "    model.add(layers.Activation('relu', name=\"Relu3_2\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"Pool3\"))\n",
    "    model.add(layers.Dropout(0.3, name=\"Drop3\")) # Slightly increased dropout\n",
    "\n",
    "    # Block 4 (Making it deeper)\n",
    "    # model.add(layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), name=\"Conv4_1\"))\n",
    "    # model.add(layers.BatchNormalization(name=\"BN4_1\"))\n",
    "    # model.add(layers.Activation('relu', name=\"Relu4_1\"))\n",
    "    # model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"Pool4\"))\n",
    "    # model.add(layers.Dropout(0.3, name=\"Drop4\"))\n",
    "\n",
    "    # --- Classification Head ---\n",
    "    model.add(layers.GlobalAveragePooling2D(name=\"GAP\"))\n",
    "    model.add(layers.Dense(128, activation='relu', kernel_regularizer=l2(l2_reg), name=\"Dense1\")) # Reduced Dense size\n",
    "    model.add(layers.Dropout(0.5, name=\"Drop_Dense\")) # Standard dropout for dense\n",
    "    model.add(layers.Dense(num_genres, activation='softmax', name=\"Output\"))\n",
    "\n",
    "    # --- Compile Model ---\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building model with input shape: (128, 1292, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Custom_CNN_Genre_Classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Custom_CNN_Genre_Classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ FreqMask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FrequencyMasking</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1292</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ TimeMask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeMasking</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1292</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1292</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1292</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1292</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1292</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1292</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1292</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">646</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">646</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">646</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">646</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">646</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">646</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">646</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">646</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">323</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">323</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">323</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">323</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">323</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv3_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">323</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">323</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu3_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">323</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GAP (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop_Dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ FreqMask (\u001b[38;5;33mFrequencyMasking\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1292\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ TimeMask (\u001b[38;5;33mTimeMasking\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1292\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1_1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1292\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1292\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu1_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1292\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1_2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1292\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1292\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu1_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1292\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m646\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop1 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m646\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv2_1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m646\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m646\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu2_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m646\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv2_2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m646\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m646\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu2_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m646\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m323\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop2 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m323\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv3_1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m323\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m323\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu3_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m323\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv3_2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m323\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m323\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu3_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m323\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop3 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GAP (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop_Dense (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">306,026</span> (1.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m306,026\u001b[0m (1.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">305,130</span> (1.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m305,130\u001b[0m (1.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Build the Model ---\n",
    "input_shape = X_train.shape[1:] # Should be (N_MELS, EXPECTED_LENGTH, 1)\n",
    "print(f\"\\nBuilding model with input shape: {input_shape}\")\n",
    "\n",
    "model = build_custom_cnn_model(input_shape, NUM_GENRES)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 7. Train the Model\n",
    "\n",
    "# --- Callbacks ---\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=BEST_MODEL_PATH,\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy', # Save based on best validation accuracy\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,     # Reduce LR by factor of 5\n",
    "        patience=7,     # Reduce if val_loss hasn't improved for 7 epochs\n",
    "        min_lr=1e-7,    # Minimum learning rate\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,    # Stop if val_loss hasn't improved for 20 epochs\n",
    "        restore_best_weights=True, # Restore weights from the epoch with best val_loss\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Model Training ---\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1745379738.235368 1404018 loop_optimizer.cc:934] Skipping loop optimization for Merge node with control input: StatefulPartitionedCall/Custom_CNN_Genre_Classifier_1/FreqMask_1/cond/branch_executed/_118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:03\u001b[0m 16s/step - accuracy: 0.1402 - loss: 3.0572"
     ]
    }
   ],
   "source": [
    "# --- Start Training ---\n",
    "print(\"\\n--- Starting Model Training ---\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val), # Use the dedicated validation set\n",
    "    callbacks=callbacks,\n",
    "    verbose=1 # Show progress bar\n",
    ")\n",
    "print(\"--- Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 8. Evaluate the Model\n",
    "\n",
    "def plot_training_history(hist):\n",
    "    \"\"\"Plots accuracy and loss curves for training and validation sets.\"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Find the epoch with the best validation accuracy\n",
    "    best_val_acc_epoch = np.argmax(hist.history['val_accuracy'])\n",
    "    best_val_acc = np.max(hist.history['val_accuracy'])\n",
    "    best_val_loss_at_best_acc = hist.history['val_loss'][best_val_acc_epoch]\n",
    "\n",
    "    # Accuracy subplot\n",
    "    axs[0].plot(hist.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "    axs[0].plot(hist.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "    axs[0].scatter(best_val_acc_epoch, best_val_acc, color='red', label=f'Best Val Acc: {best_val_acc:.4f}', zorder=5)\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].set_xlabel(\"Epoch\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].set_title(\"Accuracy Evaluation\")\n",
    "    axs[0].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Loss subplot\n",
    "    axs[1].plot(hist.history[\"loss\"], label=\"Training Loss\")\n",
    "    axs[1].plot(hist.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    axs[1].scatter(best_val_acc_epoch, best_val_loss_at_best_acc, color='red', label=f'Val Loss at Best Val Acc: {best_val_loss_at_best_acc:.4f}', zorder=5)\n",
    "    axs[1].set_ylabel(\"Loss\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Loss Evaluation\")\n",
    "    axs[1].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.suptitle(f\"Training History (Best Validation Accuracy at Epoch {best_val_acc_epoch+1})\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent title overlap\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot History ---\n",
    "print(\"\\n--- Plotting Training History ---\")\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Best Model and Evaluate on Test Set ---\n",
    "print(\"\\n--- Evaluating Best Model on Test Set ---\")\n",
    "try:\n",
    "    # Load the best model saved by ModelCheckpoint\n",
    "    # Need to provide custom objects for loading custom layers\n",
    "    custom_objects = {\n",
    "        \"FrequencyMasking\": FrequencyMasking,\n",
    "        \"TimeMasking\": TimeMasking\n",
    "    }\n",
    "    best_model = models.load_model(BEST_MODEL_PATH, custom_objects=custom_objects)\n",
    "    print(f\"Successfully loaded best model from: {BEST_MODEL_PATH}\")\n",
    "\n",
    "    test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Loss:     {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate Predictions for Reports ---\n",
    "    y_pred_prob = best_model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred_prob, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # --- Confusion Matrix ---\n",
    "    print(\"\\n--- Confusion Matrix ---\")\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=GENRES, yticklabels=GENRES)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix (Test Set)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Classification Report ---\n",
    "    print(\"\\n--- Classification Report ---\")\n",
    "    print(classification_report(y_true_classes, y_pred_classes, target_names=GENRES, digits=4))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or evaluating best model: {e}\")\n",
    "    print(\"Evaluation could not be completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 9. Test Prediction on a Sample\n",
    "\n",
    "def predict_single_genre(model_to_use, spectrogram_scaled, genres_list):\n",
    "    \"\"\" Predicts genre from a single scaled spectrogram. \"\"\"\n",
    "    if spectrogram_scaled.ndim == 3: # (height, width, channel)\n",
    "        spectrogram_scaled = spectrogram_scaled[np.newaxis, ...] # Add batch dimension (1, height, width, channel)\n",
    "    elif spectrogram_scaled.ndim != 4:\n",
    "        raise ValueError(f\"Input spectrogram has unexpected shape: {spectrogram_scaled.shape}\")\n",
    "\n",
    "    prediction = model_to_use.predict(spectrogram_scaled)[0]\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    predicted_genre = genres_list[predicted_index]\n",
    "    confidence_scores = {genre: float(score) for genre, score in zip(genres_list, prediction)}\n",
    "    return predicted_genre, confidence_scores\n",
    "\n",
    "# --- Load model if not already loaded ---\n",
    "predictor_model = None\n",
    "if 'best_model' in locals():\n",
    "    predictor_model = best_model\n",
    "else:\n",
    "    try:\n",
    "        custom_objects = {\"FrequencyMasking\": FrequencyMasking, \"TimeMasking\": TimeMasking}\n",
    "        predictor_model = models.load_model(BEST_MODEL_PATH, custom_objects=custom_objects)\n",
    "        print(f\"\\nLoaded best model from {BEST_MODEL_PATH} for prediction test.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nCould not load model for prediction test: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Perform Prediction if Model Loaded ---\n",
    "if predictor_model:\n",
    "    print(\"\\n--- Testing Prediction on Random Sample ---\")\n",
    "    # Select a random sample from the *scaled* test set\n",
    "    sample_index = np.random.randint(0, len(X_test))\n",
    "    sample_spectrogram_scaled = X_test[sample_index]\n",
    "    true_genre_index = np.argmax(y_test[sample_index])\n",
    "    true_genre = GENRES[true_genre_index]\n",
    "\n",
    "    predicted_genre, confidence_scores = predict_single_genre(predictor_model, sample_spectrogram_scaled, GENRES)\n",
    "\n",
    "    print(f\"Sample Index: {sample_index}\")\n",
    "    print(f\"True Genre:   {true_genre}\")\n",
    "    print(f\"Predicted Genre: {predicted_genre}\")\n",
    "    print(\"\\nConfidence Scores:\")\n",
    "    # Sort scores descending for display\n",
    "    for genre, score in sorted(confidence_scores.items(), key=lambda item: item[1], reverse=True):\n",
    "        print(f\"  {genre:<10}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # --- Plot the scaled spectrogram ---\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    display_spec = sample_spectrogram_scaled[:, :, 0] # Remove channel dim for plotting\n",
    "    img = librosa.display.specshow(display_spec, x_axis='time', y_axis='mel', cmap='viridis')\n",
    "    plt.colorbar(img, label='Normalized Magnitude') # Indicate it's normalized\n",
    "    plt.title(f\"Sample Spectrogram (Normalized) - True: {true_genre}, Predicted: {predicted_genre}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nSkipping prediction test as model could not be loaded.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Notebook Execution Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
