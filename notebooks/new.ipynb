{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: light\n",
    "#       format_version: '1.5'\n",
    "#       jupytext_version: 1.16.1\n",
    "#   kernelspec:\n",
    "#     display_name: Python 3 (ipykernel)\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Combined Best-Case Custom CNN for Music Genre Classification\n",
    "\n",
    "# ## Overview\n",
    "# This notebook integrates audio chunking (to increase dataset size) with a refined custom CNN architecture using best practices like global normalization, Batch Normalization, Global Average Pooling, data augmentation, and robust training procedures. It avoids transfer learning.\n",
    "#\n",
    "# **Key Features:**\n",
    "# 1.  **Audio Chunking:** Splits 30s audio files into smaller overlapping chunks.\n",
    "# 2.  **Mel Spectrogram Input:** Uses dB-scaled Mel spectrograms for each chunk.\n",
    "# 3.  **Spectrogram Resizing:** Resizes chunk spectrograms to a uniform square shape (e.g., 128x128).\n",
    "# 4.  **Global Normalization:** Applies Min-Max scaling fitted on the training set chunks.\n",
    "# 5.  **Data Augmentation:** Integrates Frequency and Time Masking layers.\n",
    "# 6.  **Refined CNN Architecture:** Deeper custom CNN with BatchNorm, GAP, L2 regularization, and Dropout.\n",
    "# 7.  **Correct Validation:** Uses a dedicated validation set (split from training data).\n",
    "# 8.  **Robust Training:** Employs EarlyStopping, ReduceLROnPlateau, ModelCheckpoint.\n",
    "# 9.  **Modern Saving Format:** Uses '.keras'.\n",
    "# 10. **Reproducibility:** Sets random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "import time # To time data processing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paths ---\n",
    "RAW_DATA_PATH = '../data/raw/GTZAN/genres_original' # Adjust path to GTZAN 'genres_original'\n",
    "MODEL_SAVE_DIR = '../model'\n",
    "BEST_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, 'best_chunked_custom_cnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Audio & Chunking Parameters ---\n",
    "SAMPLE_RATE = 22050\n",
    "TRACK_DURATION = 30 # Expected duration of original tracks\n",
    "CHUNK_DURATION_S = 4 # Duration of chunks in seconds\n",
    "CHUNK_OVERLAP_S = 2  # Overlap duration in seconds\n",
    "SAMPLES_PER_CHUNK = int(CHUNK_DURATION_S * SAMPLE_RATE)\n",
    "HOP_SAMPLES_BETWEEN_CHUNKS = int((CHUNK_DURATION_S - CHUNK_OVERLAP_S) * SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Spectrogram Parameters ---\n",
    "N_MELS = 128   # Number of Mel bands\n",
    "N_FFT = 2048   # Window size for FFT\n",
    "HOP_LENGTH = 512 # Hop length for STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Resizing Parameters ---\n",
    "# Resize spectrogram chunks to a square shape\n",
    "RESIZE_DIM = 128 # Target height and width (e.g., 128x128)\n",
    "TARGET_SHAPE = (RESIZE_DIM, RESIZE_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Genre Classes ---\n",
    "GENRES = sorted([\n",
    "    'blues', 'classical', 'country', 'disco', 'hiphop',\n",
    "    'jazz', 'metal', 'pop', 'reggae', 'rock'\n",
    "])\n",
    "NUM_GENRES = len(GENRES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Augmentation Parameters ---\n",
    "FREQ_MASK_PARAM = 25\n",
    "TIME_MASK_PARAM = 30 # Adjusted for potentially shorter time dim after resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Parameters ---\n",
    "EPOCHS = 150\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reproducibility ---\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create Model Save Directory ---\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mel_spectrogram(audio, sr=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS):\n",
    "    \"\"\"Computes the Mel spectrogram and converts it to dB scale.\"\"\"\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(\n",
    "        y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels\n",
    "    )\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    return mel_spectrogram_db\n",
    "\n",
    "def resize_spectrogram_tf(spec, target_shape=TARGET_SHAPE):\n",
    "    \"\"\"Resizes spectrogram using TensorFlow.\"\"\"\n",
    "    # Add channel dim, resize, remove channel dim\n",
    "    spec_tf = tf.constant(spec[..., np.newaxis], dtype=tf.float32)\n",
    "    resized_spec_tf = tf.image.resize(spec_tf, target_shape, method='bilinear')\n",
    "    return resized_spec_tf.numpy().squeeze() # Back to numpy array (H, W)\n",
    "\n",
    "def load_chunk_process_data(data_path, genres_list, sr=SAMPLE_RATE,\n",
    "                            chunk_samples=SAMPLES_PER_CHUNK,\n",
    "                            hop_between_chunks=HOP_SAMPLES_BETWEEN_CHUNKS,\n",
    "                            target_shape=TARGET_SHAPE):\n",
    "    \"\"\"Loads audio, creates overlapping chunks, computes, resizes Mel spectrograms.\"\"\"\n",
    "    all_spectrograms = []\n",
    "    all_labels = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"Starting data loading, chunking, and processing...\")\n",
    "    for genre_idx, genre in enumerate(genres_list):\n",
    "        genre_path = os.path.join(data_path, genre)\n",
    "        if not os.path.exists(genre_path):\n",
    "            print(f\"Warning: Path not found {genre_path}. Skipping genre.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {genre} files...\")\n",
    "        files_processed_count = 0\n",
    "        chunks_generated_count = 0\n",
    "        for filename in os.listdir(genre_path):\n",
    "            if filename.lower().endswith('.wav'):\n",
    "                file_path = os.path.join(genre_path, filename)\n",
    "                try:\n",
    "                    # Load the full audio file\n",
    "                    audio_data, current_sr = librosa.load(file_path, sr=sr, mono=True)\n",
    "\n",
    "                    # Calculate number of chunks for this file\n",
    "                    if len(audio_data) < chunk_samples:\n",
    "                        print(f\"  Skipping short file: {filename} (length {len(audio_data)} < {chunk_samples})\")\n",
    "                        continue # Skip files shorter than one chunk\n",
    "\n",
    "                    num_chunks = int(np.floor((len(audio_data) - chunk_samples) / hop_between_chunks)) + 1\n",
    "\n",
    "                    # Generate chunks and process\n",
    "                    for i in range(num_chunks):\n",
    "                        start_sample = i * hop_between_chunks\n",
    "                        end_sample = start_sample + chunk_samples\n",
    "                        chunk = audio_data[start_sample:end_sample]\n",
    "\n",
    "                        # Ensure chunk is exactly chunk_samples long (handle end cases)\n",
    "                        if len(chunk) == chunk_samples:\n",
    "                            # Compute Mel spectrogram\n",
    "                            mel_spec_db = compute_mel_spectrogram(chunk, sr=current_sr) # Uses global params\n",
    "\n",
    "                            # Resize spectrogram chunk\n",
    "                            resized_spec = resize_spectrogram_tf(mel_spec_db, target_shape)\n",
    "\n",
    "                            # Append data\n",
    "                            all_spectrograms.append(resized_spec)\n",
    "                            all_labels.append(genre_idx)\n",
    "                            chunks_generated_count += 1\n",
    "\n",
    "                    files_processed_count += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error processing file {file_path}: {e}\")\n",
    "        print(f\" -> Processed {files_processed_count} files, generated {chunks_generated_count} chunks for {genre}.\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Data loading and processing finished in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    if not all_spectrograms:\n",
    "        raise ValueError(\"No spectrograms were generated. Check paths and audio files.\")\n",
    "\n",
    "    return np.array(all_spectrograms), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data loading, chunking, and processing...\n",
      "Processing blues files...\n",
      " -> Processed 100 files, generated 1400 chunks for blues.\n",
      "Processing classical files...\n",
      " -> Processed 100 files, generated 1398 chunks for classical.\n",
      "Processing country files...\n",
      " -> Processed 100 files, generated 1397 chunks for country.\n",
      "Processing disco files...\n",
      " -> Processed 100 files, generated 1399 chunks for disco.\n",
      "Processing hiphop files...\n",
      " -> Processed 100 files, generated 1398 chunks for hiphop.\n",
      "Processing jazz files...\n",
      "  Error processing file ../data/raw/GTZAN/genres_original/jazz/jazz.00054.wav: \n",
      " -> Processed 99 files, generated 1386 chunks for jazz.\n",
      "Processing metal files...\n",
      " -> Processed 100 files, generated 1400 chunks for metal.\n",
      "Processing pop files...\n",
      " -> Processed 100 files, generated 1400 chunks for pop.\n",
      "Processing reggae files...\n",
      " -> Processed 100 files, generated 1400 chunks for reggae.\n",
      "Processing rock files...\n",
      " -> Processed 100 files, generated 1399 chunks for rock.\n",
      "Data loading and processing finished in 55.09 seconds.\n",
      "\n",
      "Total spectrogram chunks generated: 13977\n",
      "Shape of first chunk spectrogram: (128, 128)\n"
     ]
    }
   ],
   "source": [
    "# --- Execute Data Processing ---\n",
    "# This might take some time depending on your CPU/disk speed\n",
    "X_chunks_raw, y_chunks_raw = load_chunk_process_data(RAW_DATA_PATH, GENRES)\n",
    "\n",
    "print(f\"\\nTotal spectrogram chunks generated: {len(X_chunks_raw)}\")\n",
    "if len(X_chunks_raw) > 0:\n",
    "    print(f\"Shape of first chunk spectrogram: {X_chunks_raw[0].shape}\") # Should be TARGET_SHAPE\n",
    "else:\n",
    "     raise ValueError(\"Chunk list is empty after processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing chunked data for training...\n",
      "Data shape after adding channel: (13977, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# ## 4. Prepare Chunked Data for Training\n",
    "\n",
    "print(\"\\nPreparing chunked data for training...\")\n",
    "\n",
    "# --- Add Channel Dimension ---\n",
    "# Input shape should be (num_chunks, height, width)\n",
    "if X_chunks_raw.ndim == 3:\n",
    "    X = X_chunks_raw[..., np.newaxis]\n",
    "    print(f\"Data shape after adding channel: {X.shape}\") # (num_chunks, H, W, 1)\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected spectrogram array dimension: {X_chunks_raw.ndim}. Expected 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape after one-hot encoding: (13977, 10)\n"
     ]
    }
   ],
   "source": [
    "# --- Encode Labels ---\n",
    "y = to_categorical(y_chunks_raw, num_classes=NUM_GENRES)\n",
    "print(f\"Labels shape after one-hot encoding: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:   (8944, 128, 128, 1), (8944, 10)\n",
      "Validation set shape: (2237, 128, 128, 1), (2237, 10)\n",
      "Testing set shape:    (2796, 128, 128, 1), (2796, 10)\n"
     ]
    }
   ],
   "source": [
    "# --- Train/Validation/Test Split ---\n",
    "# Split into Train (80%) and Test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "# Split Train into Train (64% total) and Validation (16% total)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=SEED, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Training set shape:   {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Testing set shape:    {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying global Min-Max normalization...\n",
      "Normalization complete.\n",
      "Scaled X_train min: 0.0000, max: 1.0000\n"
     ]
    }
   ],
   "source": [
    " #--- Global Normalization (Min-Max Scaling on Chunks) ---\n",
    "print(\"Applying global Min-Max normalization...\")\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Reshape for scaler\n",
    "original_train_shape = X_train.shape\n",
    "original_val_shape = X_val.shape\n",
    "original_test_shape = X_test.shape\n",
    "\n",
    "X_train_reshaped = X_train.reshape(original_train_shape[0], -1)\n",
    "X_val_reshaped = X_val.reshape(original_val_shape[0], -1)\n",
    "X_test_reshaped = X_test.reshape(original_test_shape[0], -1)\n",
    "\n",
    "# Fit scaler ONLY on training data\n",
    "scaler.fit(X_train_reshaped)\n",
    "\n",
    "# Transform all datasets\n",
    "X_train = scaler.transform(X_train_reshaped).reshape(original_train_shape)\n",
    "X_val = scaler.transform(X_val_reshaped).reshape(original_val_shape)\n",
    "X_test = scaler.transform(X_test_reshaped).reshape(original_test_shape)\n",
    "\n",
    "print(\"Normalization complete.\")\n",
    "print(f\"Scaled X_train min: {np.min(X_train):.4f}, max: {np.max(X_train):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_keras_serializable(package=\"Custom\", name=\"FrequencyMasking\")\n",
    "class FrequencyMasking(layers.Layer):\n",
    "    \"\"\"Applies Frequency Masking augmentation.\"\"\"\n",
    "    def __init__(self, freq_mask_param, name=\"frequency_masking\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.freq_mask_param = freq_mask_param\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training is None: training = False\n",
    "        def apply_augmentation():\n",
    "            n_mels = tf.shape(inputs)[1]\n",
    "            f = tf.random.uniform(shape=(), minval=0, maxval=self.freq_mask_param + 1, dtype=tf.int32)\n",
    "            def perform_mask():\n",
    "                f0 = tf.random.uniform(shape=(), minval=0, maxval=n_mels - f, dtype=tf.int32)\n",
    "                mask_value = 0.0\n",
    "                mask = tf.concat([tf.ones(shape=(1, f0, 1, 1), dtype=inputs.dtype),\n",
    "                                  tf.fill(dims=(1, f, 1, 1), value=mask_value),\n",
    "                                  tf.ones(shape=(1, n_mels - f0 - f, 1, 1), dtype=inputs.dtype)], axis=1)\n",
    "                batch_size = tf.shape(inputs)[0]\n",
    "                mask_repeated = tf.tile(mask, [batch_size, 1, tf.shape(inputs)[2], 1])\n",
    "                return inputs * mask_repeated\n",
    "            return tf.cond(tf.greater(f, 0), true_fn=perform_mask, false_fn=lambda: inputs)\n",
    "        return tf.cond(tf.cast(training, tf.bool), true_fn=apply_augmentation, false_fn=lambda: inputs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config(); config.update({\"freq_mask_param\": self.freq_mask_param}); return config\n",
    "\n",
    "@register_keras_serializable(package=\"Custom\", name=\"TimeMasking\")\n",
    "class TimeMasking(layers.Layer):\n",
    "    \"\"\"Applies Time Masking augmentation.\"\"\"\n",
    "    def __init__(self, time_mask_param, name=\"time_masking\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.time_mask_param = time_mask_param\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training is None: training = False\n",
    "        def apply_augmentation():\n",
    "            time_steps = tf.shape(inputs)[2]\n",
    "            t = tf.random.uniform(shape=(), minval=0, maxval=self.time_mask_param + 1, dtype=tf.int32)\n",
    "            def perform_mask():\n",
    "                t0 = tf.random.uniform(shape=(), minval=0, maxval=time_steps - t, dtype=tf.int32)\n",
    "                mask_value = 0.0\n",
    "                mask = tf.concat([tf.ones(shape=(1, 1, t0, 1), dtype=inputs.dtype),\n",
    "                                  tf.fill(dims=(1, 1, t, 1), value=mask_value),\n",
    "                                  tf.ones(shape=(1, 1, time_steps - t0 - t, 1), dtype=inputs.dtype)], axis=2)\n",
    "                batch_size = tf.shape(inputs)[0]\n",
    "                mask_repeated = tf.tile(mask, [batch_size, tf.shape(inputs)[1], 1, 1])\n",
    "                return inputs * mask_repeated\n",
    "            return tf.cond(tf.greater(t, 0), true_fn=perform_mask, false_fn=lambda: inputs)\n",
    "        return tf.cond(tf.cast(training, tf.bool), true_fn=apply_augmentation, false_fn=lambda: inputs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config(); config.update({\"time_mask_param\": self.time_mask_param}); return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_refined_cnn_model(input_shape, num_genres, l2_reg=0.001):\n",
    "    \"\"\"Builds a refined custom CNN model with BatchNorm, GAP, and regularization.\"\"\"\n",
    "\n",
    "    model = models.Sequential(name=\"Refined_CNN_Genre_Classifier\")\n",
    "    model.add(layers.Input(shape=input_shape, name=\"Input_Spectrogram\"))\n",
    "\n",
    "    # Augmentation\n",
    "    model.add(FrequencyMasking(FREQ_MASK_PARAM, name=\"FreqMask\"))\n",
    "    model.add(TimeMasking(TIME_MASK_PARAM, name=\"TimeMask\"))\n",
    "\n",
    "    # --- Feature Extraction Blocks ---\n",
    "    # Block 1\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), name=\"Conv1_1\"))\n",
    "    model.add(layers.BatchNormalization(name=\"BN1_1\"))\n",
    "    model.add(layers.Activation('relu', name=\"Relu1_1\"))\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), name=\"Conv1_2\"))\n",
    "    model.add(layers.BatchNormalization(name=\"BN1_2\"))\n",
    "    model.add(layers.Activation('relu', name=\"Relu1_2\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"Pool1\"))\n",
    "    model.add(layers.Dropout(0.25, name=\"Drop1\"))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), name=\"Conv2_1\"))\n",
    "    model.add(layers.BatchNormalization(name=\"BN2_1\"))\n",
    "    model.add(layers.Activation('relu', name=\"Relu2_1\"))\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), name=\"Conv2_2\"))\n",
    "    model.add(layers.BatchNormalization(name=\"BN2_2\"))\n",
    "    model.add(layers.Activation('relu', name=\"Relu2_2\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"Pool2\"))\n",
    "    model.add(layers.Dropout(0.25, name=\"Drop2\"))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), name=\"Conv3_1\"))\n",
    "    model.add(layers.BatchNormalization(name=\"BN3_1\"))\n",
    "    model.add(layers.Activation('relu', name=\"Relu3_1\"))\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), name=\"Conv3_2\"))\n",
    "    model.add(layers.BatchNormalization(name=\"BN3_2\"))\n",
    "    model.add(layers.Activation('relu', name=\"Relu3_2\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"Pool3\"))\n",
    "    model.add(layers.Dropout(0.3, name=\"Drop3\"))\n",
    "\n",
    "    # Block 4 (Optional - Deeper Model)\n",
    "    model.add(layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), name=\"Conv4_1\"))\n",
    "    model.add(layers.BatchNormalization(name=\"BN4_1\"))\n",
    "    model.add(layers.Activation('relu', name=\"Relu4_1\"))\n",
    "    # model.add(layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=l2(l2_reg), name=\"Conv4_2\")) # Can add 2nd conv here too\n",
    "    # model.add(layers.BatchNormalization(name=\"BN4_2\"))\n",
    "    # model.add(layers.Activation('relu', name=\"Relu4_2\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), name=\"Pool4\"))\n",
    "    model.add(layers.Dropout(0.3, name=\"Drop4\"))\n",
    "    \n",
    "     # --- Classification Head ---\n",
    "    model.add(layers.GlobalAveragePooling2D(name=\"GAP\"))\n",
    "    model.add(layers.Dense(128, activation='relu', kernel_regularizer=l2(l2_reg), name=\"Dense1\"))\n",
    "    model.add(layers.Dropout(0.5, name=\"Drop_Dense\"))\n",
    "    model.add(layers.Dense(num_genres, activation='softmax', name=\"Output_Softmax\"))\n",
    "     # --- Compile Model ---\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building model with input shape: (128, 128, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Refined_CNN_Genre_Classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Refined_CNN_Genre_Classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ FreqMask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FrequencyMasking</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ TimeMask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeMasking</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv3_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu3_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv4_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN4_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu4_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GAP (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop_Dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ FreqMask (\u001b[38;5;33mFrequencyMasking\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ TimeMask (\u001b[38;5;33mTimeMasking\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1_1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu1_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1_2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN1_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu1_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop1 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv2_1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu2_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv2_2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN2_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu2_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop2 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv3_1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu3_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv3_2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN3_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu3_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop3 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv4_1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BN4_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Relu4_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop4 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GAP (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Drop_Dense (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Softmax (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">618,602</span> (2.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m618,602\u001b[0m (2.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">617,194</span> (2.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m617,194\u001b[0m (2.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> (5.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,408\u001b[0m (5.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Build the Model ---\n",
    "input_shape = X_train.shape[1:] # Should be (RESIZE_DIM, RESIZE_DIM, 1)\n",
    "print(f\"\\nBuilding model with input shape: {input_shape}\")\n",
    "\n",
    "model = build_refined_cnn_model(input_shape, NUM_GENRES)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 7. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Callbacks ---\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=BEST_MODEL_PATH, save_best_only=True, monitor='val_accuracy', verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7, verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=20, restore_best_weights=True, verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Model Training ---\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1745470737.536644  346419 loop_optimizer.cc:934] Skipping loop optimization for Merge node with control input: StatefulPartitionedCall/Refined_CNN_Genre_Classifier_1/FreqMask_1/cond/branch_executed/_133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m109/280\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:51\u001b[0m 1s/step - accuracy: 0.1428 - loss: 3.3023   "
     ]
    }
   ],
   "source": [
    "# --- Start Training ---\n",
    "print(\"\\n--- Starting Model Training ---\")\n",
    "# Note: Training will take longer now due to more data (chunks)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val), # Use the dedicated validation set\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"--- Training Complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 8. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(hist, model_name=\"Model\"):\n",
    "    \"\"\"Plots accuracy and loss curves.\"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    best_val_acc_epoch = np.argmax(hist.history['val_accuracy'])\n",
    "    best_val_acc = np.max(hist.history['val_accuracy'])\n",
    "    val_loss_at_best_acc = hist.history['val_loss'][best_val_acc_epoch]\n",
    "\n",
    "    # Accuracy\n",
    "    axs[0].plot(hist.history[\"accuracy\"], label=\"Training Accuracy\", marker='.')\n",
    "    axs[0].plot(hist.history[\"val_accuracy\"], label=\"Validation Accuracy\", marker='.')\n",
    "    axs[0].scatter(best_val_acc_epoch, best_val_acc, color='red', s=100, label=f'Best Val Acc: {best_val_acc:.4f}', zorder=5)\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].set_xlabel(\"Epoch\")\n",
    "    axs[0].legend(loc=\"best\")\n",
    "    axs[0].set_title(f\"{model_name} - Accuracy\")\n",
    "    axs[0].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Loss\n",
    "    axs[1].plot(hist.history[\"loss\"], label=\"Training Loss\", marker='.')\n",
    "    axs[1].plot(hist.history[\"val_loss\"], label=\"Validation Loss\", marker='.')\n",
    "    axs[1].scatter(best_val_acc_epoch, val_loss_at_best_acc, color='red', s=100, label=f'Val Loss: {val_loss_at_best_acc:.4f}', zorder=5)\n",
    "    axs[1].set_ylabel(\"Loss\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].legend(loc=\"best\")\n",
    "    axs[1].set_title(f\"{model_name} - Loss\")\n",
    "    axs[1].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.suptitle(f\"Training History (Best Validation Acc. Epoch {best_val_acc_epoch+1})\", fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot History ---\n",
    "print(\"\\n--- Plotting Training History ---\")\n",
    "plot_training_history(history, \"Refined Custom CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Best Model and Evaluate on Test Set ---\n",
    "print(\"\\n--- Evaluating Best Model on Test Set ---\")\n",
    "best_model = None # Initialize\n",
    "try:\n",
    "    custom_objects = {\"FrequencyMasking\": FrequencyMasking, \"TimeMasking\": TimeMasking}\n",
    "    best_model = models.load_model(BEST_MODEL_PATH, custom_objects=custom_objects)\n",
    "    print(f\"Successfully loaded best model from: {BEST_MODEL_PATH}\")\n",
    "\n",
    "    test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0, batch_size=BATCH_SIZE) # Use batch_size for eval too\n",
    "    print(f\"Test Loss:     {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # --- Generate Predictions for Reports ---\n",
    "    y_pred_prob = best_model.predict(X_test, batch_size=BATCH_SIZE) # Use batch_size for predict too\n",
    "    y_pred_classes = np.argmax(y_pred_prob, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # --- Confusion Matrix ---\n",
    "    print(\"\\n--- Confusion Matrix ---\")\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=GENRES, yticklabels=GENRES)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix (Test Set)')\n",
    "    plt.show()\n",
    "\n",
    "    # --- Classification Report ---\n",
    "    print(\"\\n--- Classification Report ---\")\n",
    "    print(classification_report(y_true_classes, y_pred_classes, target_names=GENRES, digits=4))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or evaluating best model: {e}\")\n",
    "    print(\"Evaluation could not be completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 9. Test Prediction on a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_genre(model_to_use, spectrogram_scaled, genres_list):\n",
    "    \"\"\" Predicts genre from a single scaled spectrogram chunk. \"\"\"\n",
    "    if spectrogram_scaled.ndim == 3: # (height, width, channel)\n",
    "        spectrogram_scaled = spectrogram_scaled[np.newaxis, ...] # Add batch dimension\n",
    "    elif spectrogram_scaled.ndim != 4:\n",
    "        raise ValueError(f\"Input spectrogram has unexpected shape: {spectrogram_scaled.shape}\")\n",
    "\n",
    "    prediction = model_to_use.predict(spectrogram_scaled, verbose=0)[0] # Add verbose=0\n",
    "\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    predicted_genre = genres_list[predicted_index]\n",
    "    confidence_scores = {genre: float(score) for genre, score in zip(genres_list, prediction)}\n",
    "    return predicted_genre, confidence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load model if not already loaded ---\n",
    "predictor_model = None\n",
    "if 'best_model' in locals() and best_model is not None:\n",
    "    predictor_model = best_model\n",
    "    print(\"\\nUsing best model loaded from evaluation section.\")\n",
    "else:\n",
    "    try:\n",
    "        custom_objects = {\"FrequencyMasking\": FrequencyMasking, \"TimeMasking\": TimeMasking}\n",
    "        predictor_model = models.load_model(BEST_MODEL_PATH, custom_objects=custom_objects)\n",
    "        print(f\"\\nLoaded best model from {BEST_MODEL_PATH} for prediction test.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nCould not load best model for prediction test: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Perform Prediction if Model Loaded ---\n",
    "if predictor_model:\n",
    "    print(\"\\n--- Testing Prediction on Random Sample ---\")\n",
    "    # Select a random sample from the *scaled* test set\n",
    "    sample_index = np.random.randint(0, len(X_test))\n",
    "    sample_spectrogram_scaled = X_test[sample_index]\n",
    "    true_genre_index = np.argmax(y_test[sample_index])\n",
    "    true_genre = GENRES[true_genre_index]\n",
    "\n",
    "    predicted_genre, confidence_scores = predict_single_genre(predictor_model, sample_spectrogram_scaled, GENRES)\n",
    "\n",
    "    print(f\"Sample Index: {sample_index}\")\n",
    "    print(f\"True Genre:   {true_genre}\")\n",
    "    print(f\"Predicted Genre: {predicted_genre}\")\n",
    "    print(\"\\nConfidence Scores:\")\n",
    "    for genre, score in sorted(confidence_scores.items(), key=lambda item: item[1], reverse=True):\n",
    "        print(f\"  {genre:<10}: {score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # --- Plot the scaled spectrogram ---\n",
    "    plt.figure(figsize=(8, 6)) # Adjusted size for square-ish plot\n",
    "    display_spec = sample_spectrogram_scaled[:, :, 0] # Remove channel dim\n",
    "    img = librosa.display.specshow(display_spec, cmap='viridis') # Basic display for resized\n",
    "    plt.colorbar(img, label='Normalized Magnitude')\n",
    "    plt.title(f\"Sample Spectrogram Chunk (Normalized & Resized {RESIZE_DIM}x{RESIZE_DIM})\\nTrue: {true_genre}, Predicted: {predicted_genre}\")\n",
    "    plt.xlabel(\"Time (Resized)\")\n",
    "    plt.ylabel(\"Mel Frequency (Resized)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nSkipping prediction test as model could not be loaded.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Notebook Execution Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
