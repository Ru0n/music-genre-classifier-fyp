{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification - Model Training\n",
    "\n",
    "This notebook demonstrates the process of training a Convolutional Neural Network (CNN) for music genre classification using the GTZAN dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "DATA_PATH = '../data/raw/gtzan'\n",
    "\n",
    "# Audio parameters\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 30  # seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "# Spectrogram parameters\n",
    "N_MELS = 128\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "\n",
    "# Genre classes (GTZAN dataset)\n",
    "GENRES = [\n",
    "    'blues',\n",
    "    'classical',\n",
    "    'country',\n",
    "    'disco',\n",
    "    'hiphop',\n",
    "    'jazz',\n",
    "    'metal',\n",
    "    'pop',\n",
    "    'reggae',\n",
    "    'rock'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    \"\"\"\n",
    "    Load audio files and generate spectrograms\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): Path to the dataset\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (spectrograms, labels)\n",
    "    \"\"\"\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    \n",
    "    # Process each genre folder\n",
    "    for genre_idx, genre in enumerate(GENRES):\n",
    "        genre_path = os.path.join(data_path, genre)\n",
    "        \n",
    "        # Skip if folder doesn't exist\n",
    "        if not os.path.exists(genre_path):\n",
    "            print(f\"Warning: {genre_path} does not exist. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Processing {genre} files...\")\n",
    "        \n",
    "        # Process each audio file in the genre folder\n",
    "        for filename in os.listdir(genre_path):\n",
    "            if not filename.endswith('.wav'):\n",
    "                continue\n",
    "                \n",
    "            # Load audio file\n",
    "            file_path = os.path.join(genre_path, filename)\n",
    "            y, sr = librosa.load(file_path, sr=SAMPLE_RATE, mono=True)\n",
    "            \n",
    "            # Generate Mel spectrogram\n",
    "            mel_spectrogram = librosa.feature.melspectrogram(\n",
    "                y=y,\n",
    "                sr=sr,\n",
    "                n_fft=N_FFT,\n",
    "                hop_length=HOP_LENGTH,\n",
    "                n_mels=N_MELS\n",
    "            )\n",
    "            \n",
    "            # Convert to dB scale\n",
    "            mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "            \n",
    "            # Add to dataset\n",
    "            spectrograms.append(mel_spectrogram_db)\n",
    "            labels.append(genre_idx)\n",
    "    \n",
    "    return np.array(spectrograms), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# Note: This will take some time to process all audio files\n",
    "# spectrograms, labels = load_data(DATA_PATH)\n",
    "\n",
    "# For demonstration purposes, we'll create dummy data\n",
    "# In a real implementation, you would use the load_data function above\n",
    "\n",
    "# Create dummy spectrograms (10 samples per genre)\n",
    "num_samples = 10 * len(GENRES)\n",
    "dummy_spectrograms = np.random.rand(num_samples, N_MELS, 1292)  # 1292 is an example time dimension\n",
    "dummy_labels = np.repeat(np.arange(len(GENRES)), 10)\n",
    "\n",
    "spectrograms = dummy_spectrograms\n",
    "labels = dummy_labels\n",
    "\n",
    "print(f\"Loaded {len(spectrograms)} spectrograms with shape {spectrograms[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add channel dimension for CNN\n",
    "X = spectrograms[..., np.newaxis]\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y = to_categorical(labels, num_classes=len(GENRES))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Testing set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    \"\"\"\n",
    "    Build a CNN model for music genre classification\n",
    "    \n",
    "    Args:\n",
    "        input_shape (tuple): Shape of input data\n",
    "        \n",
    "    Returns:\n",
    "        tf.keras.Model: Compiled model\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # First convolutional block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        # Second convolutional block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        # Third convolutional block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(len(GENRES), activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "input_shape = X_train[0].shape\n",
    "model = build_model(input_shape)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2)\n",
    "]\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model directory if it doesn't exist\n",
    "model_dir = '../model'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(model_dir, 'genre_classifier_model.h5')\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genre(model, spectrogram):\n",
    "    \"\"\"\n",
    "    Predict genre from spectrogram\n",
    "    \n",
    "    Args:\n",
    "        model (tf.keras.Model): Trained model\n",
    "        spectrogram (numpy.ndarray): Mel spectrogram\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (predicted_genre, confidence_scores)\n",
    "    \"\"\"\n",
    "    # Add batch and channel dimensions\n",
    "    spectrogram = spectrogram.reshape(1, *spectrogram.shape, 1)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(spectrogram)[0]\n",
    "    \n",
    "    # Get predicted genre and confidence\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    predicted_genre = GENRES[predicted_index]\n",
    "    confidence = prediction[predicted_index]\n",
    "    \n",
    "    # Get confidence scores for all genres\n",
    "    confidence_scores = {genre: float(score) for genre, score in zip(GENRES, prediction)}\n",
    "    \n",
    "    return predicted_genre, confidence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction on a sample from the test set\n",
    "sample_index = np.random.randint(0, len(X_test))\n",
    "sample_spectrogram = X_test[sample_index, :, :, 0]  # Remove channel dimension\n",
    "true_genre = GENRES[np.argmax(y_test[sample_index])]\n",
    "\n",
    "# Predict genre\n",
    "predicted_genre, confidence_scores = predict_genre(model, sample_spectrogram)\n",
    "\n",
    "print(f\"True genre: {true_genre}\")\n",
    "print(f\"Predicted genre: {predicted_genre}\")\n",
    "print(\"\\nConfidence scores:\")\n",
    "for genre, score in sorted(confidence_scores.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{genre}: {score:.4f}\")\n",
    "\n",
    "# Plot spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(\n",
    "    sample_spectrogram,\n",
    "    sr=SAMPLE_RATE,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    x_axis='time',\n",
    "    y_axis='mel'\n",
    ")\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title(f\"Mel Spectrogram - True: {true_genre}, Predicted: {predicted_genre}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
